{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import efficientnet.keras as efn \n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "#from tensorflow.keras import backend\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "from kapre.time_frequency import Spectrogram\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#!rm -r train_data\n",
    "#!rm -r val_data\n",
    "#!rm -r models\n",
    "#!mkdir models\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fix for RTX2080 CTRNN memory alloc issues\n",
    "SOUND_DIR = \"/project/data/birdsong-recognition/train_audio/\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating Mel Spectrogram\n",
    "def createMelSpectrogram(input_path, fileName, output_path, saveOrShow=0):\n",
    "    print(\"creating for\",fileName)\n",
    "    if (os.path.isdir(os.path.join(input_path, fileName))):\n",
    "        return\n",
    "    \n",
    "    # load sound signal\n",
    "    signal, sr = librosa.load(os.path.join(input_path, fileName), duration=10)\n",
    "    \n",
    "    # create Mel Spectrogram\n",
    "    S = Melspectrogram(n_dft=1024, \n",
    "                       n_hop=256,\n",
    "                       input_shape=(1, signal.shape[0]),\n",
    "                       padding='same', sr=sr, n_mels=224, fmin=1400, fmax=sr/2,\n",
    "                       power_melgram=2.0, return_decibel_melgram=True,\n",
    "                       trainable_fb=False, trainable_kernel=False)(signal.reshape(1, 1, -1)).numpy()\n",
    "    \n",
    "    S = S.reshape(S.shape[1], S.shape[2])\n",
    "    \n",
    "    ##### NOTE CHANGE TO FILENAME INDEX TO CORRECTLY PROCESS AUGMENT\n",
    "    ##### FILES THAT CONTAIN A. PREFIXES AND OTHER DOTS BEFORE \".mp3\"\n",
    "    if saveOrShow == 0:   \n",
    "        print(\"writing out\", os.path.join(output_path, fileName[:-4] + \".png\"))\n",
    "        matplotlib.image.imsave(os.path.join(output_path, fileName[:-4] + \".png\"), S)\n",
    "    else:\n",
    "        #plt.imshow(S)\n",
    "        #plt.show()\n",
    "        display.specshow(S, sr=sr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Mel-Spectrogram of an audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bird: aldfly\n",
    "createMelSpectrogram(SOUND_DIR+\"aldfly\", \"XC134874.mp3\", \"\", 1)\n",
    "createMelSpectrogram(SOUND_DIR+\"aldfly\", \"XC16967.mp3\", \"\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bird: ameavo\n",
    "createMelSpectrogram(SOUND_DIR+\"ameavo\", \"XC133080.mp3\", \"\", 1)\n",
    "createMelSpectrogram(SOUND_DIR+\"ameavo\", \"XC139829.mp3\", \"\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mel-Spectrogram for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 20 birds for training\n",
    "BIRDS = os.listdir(\"data/birdsong-recognition/train_audio/\")[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amered yelwar semsan horlar vigswa blugrb1 cedwax sposan brthum gockin belkin1 olsfly whbnut commer wewpew moudov wilsni1 pasfly gryfly annhum "
     ]
    }
   ],
   "source": [
    "BIRDS\n",
    "\n",
    "for bird in BIRDS:\n",
    "    print(bird,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of birds\n",
    "#BIRDS = [\"aldfly\", \"ameavo\", \"amebit\", \"amecro\", \"amegfi\",\n",
    "#         \"amekes\", \"amepip\", \"amered\", \"amerob\", \"amewig\"]\n",
    "\n",
    "train_folder = \"data/train_data_decibel_20/\"\n",
    "val_folder = \"data/val_data_decibel_20/\"\n",
    "\n",
    "if not os.path.exists(train_folder): os.mkdir(train_folder)\n",
    "if not os.path.exists(val_folder): os.mkdir(val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_to_mel(bird):\n",
    "    print(bird, \"\\n\")\n",
    "    INPUT_DIR = os.path.join(\"data/birdsong-recognition/train_audio/\", bird)\n",
    "    TRAIN_DIR = os.path.join(train_folder, bird)\n",
    "    VAL_DIR = os.path.join(val_folder, bird)\n",
    "    \n",
    "    # create folders\n",
    "    if not(os.path.exists(TRAIN_DIR)) and not(os.path.exists(VAL_DIR)): \n",
    "        \n",
    "        os.mkdir(TRAIN_DIR)\n",
    "        os.mkdir(VAL_DIR)\n",
    "\n",
    "        \n",
    "        # split into train and val set\n",
    "        for f in os.listdir(INPUT_DIR):\n",
    "            \n",
    "            rand = np.random.randint(0, 10)\n",
    "\n",
    "            if rand <= 7: \n",
    "                createMelSpectrogram(INPUT_DIR, f, TRAIN_DIR)\n",
    "            else:\n",
    "                createMelSpectrogram(INPUT_DIR, f, VAL_DIR)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 31 threads\n",
      "ameredsemsanyelwarvigswahorlarblugrb1sposancedwaxgockinbrthumbelkin1  whbnutcommerolsflymoudovwewpewwilsni1 pasfly gryfly  annhum    \n",
      "\n",
      "       \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This takes long time to run ###\n",
    "\n",
    "## Needed to manualy rename the train and validation data directories\n",
    "## to force it to be recreated with the full data set\n",
    "\n",
    "# create train and val spectrogram\n",
    "np.random.seed(1234)\n",
    "\n",
    "threads = int((mp.cpu_count() /2) - 1)\n",
    "# threads = int(mp.cpu_count() -2)\n",
    "# threads = 48\n",
    "\n",
    "# Handle single-core machines\n",
    "if (threads < 1): threads = 1\n",
    "print(f\"Launching {threads} threads\")\n",
    "pool = mp.Pool(threads)\n",
    "\n",
    "pool.map(bird_to_mel, BIRDS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = (224,224,3)\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15128 images belonging to 20 classes.\n",
      "Found 3872 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=None,\n",
    "                                   rescale=1/255,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(train_folder,\n",
    "                                                  classes=BIRDS, \n",
    "                                                  target_size=IM_SIZE[0:2], \n",
    "                                                  class_mode='categorical', \n",
    "                                                  shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=None, rescale=1/255)\n",
    "\n",
    "val_batches = train_datagen.flow_from_directory(val_folder,\n",
    "                                                  classes=BIRDS, \n",
    "                                                  target_size=IM_SIZE[0:2], \n",
    "                                                  class_mode='categorical', \n",
    "                                                  shuffle=False, batch_size=1)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  np.unique(train_batches.classes), \n",
    "                                                  train_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = efn.EfficientNetB3(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=IM_SIZE)\n",
    "#net.trainable = False\n",
    "\n",
    "x = net.output\n",
    "\n",
    "#x1 = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x2 = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "#x = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(len(BIRDS), activation='softmax', name='softmax')(x)\n",
    "net_final = tf.keras.Model(inputs=net.input, outputs=output_layer)\n",
    "\n",
    "net_final.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### %%time\n",
    "ModelCheck = tf.keras.callbacks.ModelCheckpoint('models/efficientnet_checkpoint.h5', monitor='val_loss', verbose=0, \n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "net_final.reset_states()\n",
    "net_final.fit_generator(train_batches, \n",
    "                        validation_data=val_batches,\n",
    "                        steps_per_epoch = int(len(train_batches.classes)/BATCH_SIZE)+1,\n",
    "                        validation_steps=len(val_batches.classes),\n",
    "                        epochs=60, \n",
    "                        callbacks=[ModelCheck],\n",
    "                       class_weight={i:class_weights[i] for i in range(len(BIRDS))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on val data\n",
      "3872/3872 [==============================] - 56s 14ms/step - loss: 0.7076 - accuracy: 0.8409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8409090638160706"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_final.load_weights('models/efficientnet_checkpoint.h5')\n",
    "print(\"Accuracy on val data\")\n",
    "net_final.evaluate(val_batches, steps=len(val_batches.classes))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_final.save(\"models/net_final_augmented_data_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_final.save_weights(\"models/net_final_augmented_data_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/net_final_augmented_data_1.pb/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(net_final, \"models/net_final_augmented_data_1.pb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
