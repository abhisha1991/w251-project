{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import efficientnet.keras as efn \n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "#from tensorflow.keras import backend\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "from kapre.time_frequency import Spectrogram\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#!rm -r train_data\n",
    "#!rm -r val_data\n",
    "#!rm -r models\n",
    "#!mkdir models\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fix for RTX2080 CTRNN memory alloc issues\n",
    "SOUND_DIR = \"/project/data/birdsong-recognition/train_audio/\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating Mel Spectrogram\n",
    "def createMelSpectrogram(input_path, fileName, output_path, saveOrShow=0):\n",
    "    print(\"creating for\",fileName)\n",
    "    if (os.path.isdir(os.path.join(input_path, fileName))):\n",
    "        return\n",
    "    \n",
    "    # load sound signal\n",
    "    signal, sr = librosa.load(os.path.join(input_path, fileName), duration=10)\n",
    "    \n",
    "    # create Mel Spectrogram\n",
    "    S = Melspectrogram(n_dft=1024, \n",
    "                       n_hop=256,\n",
    "                       input_shape=(1, signal.shape[0]),\n",
    "                       padding='same', sr=sr, n_mels=224, fmin=1400, fmax=sr/2,\n",
    "                       power_melgram=2.0, return_decibel_melgram=True,\n",
    "                       trainable_fb=False, trainable_kernel=False)(signal.reshape(1, 1, -1)).numpy()\n",
    "    \n",
    "    S = S.reshape(S.shape[1], S.shape[2])\n",
    "    \n",
    "    ##### NOTE CHANGE TO FILENAME INDEX TO CORRECTLY PROCESS AUGMENT\n",
    "    ##### FILES THAT CONTAIN A. PREFIXES AND OTHER DOTS BEFORE \".mp3\"\n",
    "    if saveOrShow == 0:   \n",
    "        print(\"writing out\", os.path.join(output_path, fileName[:-4] + \".png\"))\n",
    "        matplotlib.image.imsave(os.path.join(output_path, fileName[:-4] + \".png\"), S)\n",
    "    else:\n",
    "        #plt.imshow(S)\n",
    "        #plt.show()\n",
    "        display.specshow(S, sr=sr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Mel-Spectrogram of an audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bird: aldfly\n",
    "createMelSpectrogram(SOUND_DIR+\"aldfly\", \"XC134874.mp3\", \"\", 1)\n",
    "createMelSpectrogram(SOUND_DIR+\"aldfly\", \"XC16967.mp3\", \"\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bird: ameavo\n",
    "createMelSpectrogram(SOUND_DIR+\"ameavo\", \"XC133080.mp3\", \"\", 1)\n",
    "createMelSpectrogram(SOUND_DIR+\"ameavo\", \"XC139829.mp3\", \"\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mel-Spectrogram for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 20 birds for training\n",
    "BIRDS = os.listdir(\"data/birdsong-recognition/train_audio/\")[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amered',\n",
       " 'yelwar',\n",
       " 'semsan',\n",
       " 'horlar',\n",
       " 'vigswa',\n",
       " 'blugrb1',\n",
       " 'cedwax',\n",
       " 'sposan',\n",
       " 'brthum',\n",
       " 'gockin',\n",
       " 'belkin1',\n",
       " 'olsfly',\n",
       " 'whbnut',\n",
       " 'commer',\n",
       " 'wewpew',\n",
       " 'moudov',\n",
       " 'wilsni1',\n",
       " 'pasfly',\n",
       " 'gryfly',\n",
       " 'annhum']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of birds\n",
    "#BIRDS = [\"aldfly\", \"ameavo\", \"amebit\", \"amecro\", \"amegfi\",\n",
    "#         \"amekes\", \"amepip\", \"amered\", \"amerob\", \"amewig\"]\n",
    "\n",
    "train_folder = \"data/train_data_decibel_20/\"\n",
    "val_folder = \"data/val_data_decibel_20/\"\n",
    "\n",
    "if not os.path.exists(train_folder): os.mkdir(train_folder)\n",
    "if not os.path.exists(val_folder): os.mkdir(val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_to_mel(bird):\n",
    "    print(bird, \"\\n\")\n",
    "    INPUT_DIR = os.path.join(\"data/birdsong-recognition/train_audio/\", bird)\n",
    "    TRAIN_DIR = os.path.join(train_folder, bird)\n",
    "    VAL_DIR = os.path.join(val_folder, bird)\n",
    "    \n",
    "    # create folders\n",
    "    if not(os.path.exists(TRAIN_DIR)) and not(os.path.exists(VAL_DIR)): \n",
    "        \n",
    "        os.mkdir(TRAIN_DIR)\n",
    "        os.mkdir(VAL_DIR)\n",
    "\n",
    "        \n",
    "        # split into train and val set\n",
    "        for f in os.listdir(INPUT_DIR):\n",
    "            \n",
    "            rand = np.random.randint(0, 10)\n",
    "\n",
    "            if rand <= 7: \n",
    "                createMelSpectrogram(INPUT_DIR, f, TRAIN_DIR)\n",
    "            else:\n",
    "                createMelSpectrogram(INPUT_DIR, f, VAL_DIR)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 31 threads\n",
      "yelwarameredhorlarsemsancedwaxblugrb1sposanvigswabrthumbelkin1olsflygockincommer  whbnutwewpew  moudovwilsni1  gryflypasfly  annhum   \n",
      "   \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "  \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This takes long time to run ###\n",
    "\n",
    "## Needed to manualy rename the train and validation data directories\n",
    "## to force it to be recreated with the full data set\n",
    "\n",
    "# create train and val spectrogram\n",
    "np.random.seed(1234)\n",
    "\n",
    "threads = int((mp.cpu_count() /2) - 1)\n",
    "# threads = int(mp.cpu_count() -2)\n",
    "# threads = 48\n",
    "\n",
    "# Handle single-core machines\n",
    "if (threads < 1): threads = 1\n",
    "print(f\"Launching {threads} threads\")\n",
    "pool = mp.Pool(threads)\n",
    "\n",
    "pool.map(bird_to_mel, BIRDS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = (224,224,3)\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15133 images belonging to 20 classes.\n",
      "Found 3867 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=None,\n",
    "                                   rescale=1/255,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(train_folder,\n",
    "                                                  classes=BIRDS, \n",
    "                                                  target_size=IM_SIZE[0:2], \n",
    "                                                  class_mode='categorical', \n",
    "                                                  shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=None, rescale=1/255)\n",
    "\n",
    "val_batches = train_datagen.flow_from_directory(val_folder,\n",
    "                                                  classes=BIRDS, \n",
    "                                                  target_size=IM_SIZE[0:2], \n",
    "                                                  class_mode='categorical', \n",
    "                                                  shuffle=False, batch_size=1)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  np.unique(train_batches.classes), \n",
    "                                                  train_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = efn.EfficientNetB3(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=IM_SIZE)\n",
    "#net.trainable = False\n",
    "\n",
    "x = net.output\n",
    "\n",
    "#x1 = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x2 = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "#x = tf.keras.layers.Concatenate(axis=1)([x1, x2])\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(len(BIRDS), activation='softmax', name='softmax')(x)\n",
    "net_final = tf.keras.Model(inputs=net.input, outputs=output_layer)\n",
    "\n",
    "net_final.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-47b3c763374f>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/60\n",
      "1514/1514 [==============================] - 246s 162ms/step - loss: 1.8413 - accuracy: 0.4542 - val_loss: 1.5681 - val_accuracy: 0.6033\n",
      "Epoch 2/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 1.1271 - accuracy: 0.6658 - val_loss: 1.1338 - val_accuracy: 0.6897\n",
      "Epoch 3/60\n",
      "1514/1514 [==============================] - 247s 163ms/step - loss: 0.8762 - accuracy: 0.7406 - val_loss: 0.8772 - val_accuracy: 0.7623\n",
      "Epoch 4/60\n",
      "1514/1514 [==============================] - 245s 162ms/step - loss: 0.7076 - accuracy: 0.7938 - val_loss: 0.8177 - val_accuracy: 0.7848\n",
      "Epoch 5/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.5891 - accuracy: 0.8246 - val_loss: 0.7148 - val_accuracy: 0.8477\n",
      "Epoch 6/60\n",
      "1514/1514 [==============================] - 244s 161ms/step - loss: 0.4981 - accuracy: 0.8552 - val_loss: 0.4084 - val_accuracy: 0.8893\n",
      "Epoch 7/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.4301 - accuracy: 0.8707 - val_loss: 0.5501 - val_accuracy: 0.8738\n",
      "Epoch 8/60\n",
      "1514/1514 [==============================] - 240s 159ms/step - loss: 0.4054 - accuracy: 0.8818 - val_loss: 0.4544 - val_accuracy: 0.8640\n",
      "Epoch 9/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.3542 - accuracy: 0.8938 - val_loss: 0.4766 - val_accuracy: 0.8847\n",
      "Epoch 10/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.3410 - accuracy: 0.8984 - val_loss: 0.3992 - val_accuracy: 0.8968\n",
      "Epoch 11/60\n",
      "1514/1514 [==============================] - 245s 162ms/step - loss: 0.2901 - accuracy: 0.9126 - val_loss: 0.3144 - val_accuracy: 0.9185\n",
      "Epoch 12/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.2928 - accuracy: 0.9122 - val_loss: 0.4561 - val_accuracy: 0.8764\n",
      "Epoch 13/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.2413 - accuracy: 0.9279 - val_loss: 0.3456 - val_accuracy: 0.9266\n",
      "Epoch 14/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.2555 - accuracy: 0.9235 - val_loss: 0.3222 - val_accuracy: 0.9147\n",
      "Epoch 15/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.2151 - accuracy: 0.9364 - val_loss: 0.2584 - val_accuracy: 0.9289\n",
      "Epoch 16/60\n",
      "1514/1514 [==============================] - 245s 162ms/step - loss: 0.2050 - accuracy: 0.9368 - val_loss: 0.7861 - val_accuracy: 0.8182\n",
      "Epoch 17/60\n",
      "1514/1514 [==============================] - 244s 161ms/step - loss: 0.1950 - accuracy: 0.9409 - val_loss: 0.2734 - val_accuracy: 0.9320\n",
      "Epoch 18/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.1876 - accuracy: 0.9434 - val_loss: 0.2878 - val_accuracy: 0.9338\n",
      "Epoch 19/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.1785 - accuracy: 0.9469 - val_loss: 0.2518 - val_accuracy: 0.9390\n",
      "Epoch 20/60\n",
      "1514/1514 [==============================] - 239s 158ms/step - loss: 0.1647 - accuracy: 0.9483 - val_loss: 0.2538 - val_accuracy: 0.9346\n",
      "Epoch 21/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.1459 - accuracy: 0.9565 - val_loss: 0.3225 - val_accuracy: 0.9263\n",
      "Epoch 22/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.1427 - accuracy: 0.9563 - val_loss: 0.4636 - val_accuracy: 0.9048\n",
      "Epoch 23/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.1390 - accuracy: 0.9562 - val_loss: 0.6667 - val_accuracy: 0.8800\n",
      "Epoch 24/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.1521 - accuracy: 0.9538 - val_loss: 0.3101 - val_accuracy: 0.9304\n",
      "Epoch 25/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.1301 - accuracy: 0.9593 - val_loss: 0.2752 - val_accuracy: 0.9377\n",
      "Epoch 26/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.1356 - accuracy: 0.9592 - val_loss: 0.2614 - val_accuracy: 0.9428\n",
      "Epoch 27/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.1168 - accuracy: 0.9632 - val_loss: 0.2715 - val_accuracy: 0.9405\n",
      "Epoch 28/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.1280 - accuracy: 0.9604 - val_loss: 0.2306 - val_accuracy: 0.9480\n",
      "Epoch 29/60\n",
      "1514/1514 [==============================] - 244s 161ms/step - loss: 0.1321 - accuracy: 0.9593 - val_loss: 0.2603 - val_accuracy: 0.9390\n",
      "Epoch 30/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.1148 - accuracy: 0.9635 - val_loss: 0.2149 - val_accuracy: 0.9524\n",
      "Epoch 31/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.1051 - accuracy: 0.9674 - val_loss: 0.2095 - val_accuracy: 0.9522\n",
      "Epoch 32/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.1176 - accuracy: 0.9632 - val_loss: 0.2323 - val_accuracy: 0.9475\n",
      "Epoch 33/60\n",
      "1514/1514 [==============================] - 244s 161ms/step - loss: 0.1065 - accuracy: 0.9691 - val_loss: 0.2194 - val_accuracy: 0.9488\n",
      "Epoch 34/60\n",
      "1514/1514 [==============================] - 246s 163ms/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.2437 - val_accuracy: 0.9493\n",
      "Epoch 35/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0967 - accuracy: 0.9694 - val_loss: 0.2245 - val_accuracy: 0.9516\n",
      "Epoch 36/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.1032 - accuracy: 0.9671 - val_loss: 0.2157 - val_accuracy: 0.9568\n",
      "Epoch 37/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.0864 - accuracy: 0.9746 - val_loss: 0.2478 - val_accuracy: 0.9467\n",
      "Epoch 38/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0940 - accuracy: 0.9709 - val_loss: 0.4368 - val_accuracy: 0.8960\n",
      "Epoch 39/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0894 - accuracy: 0.9724 - val_loss: 0.2443 - val_accuracy: 0.9491\n",
      "Epoch 40/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0891 - accuracy: 0.9725 - val_loss: 0.2279 - val_accuracy: 0.9545\n",
      "Epoch 41/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0905 - accuracy: 0.9734 - val_loss: 0.2859 - val_accuracy: 0.9416\n",
      "Epoch 42/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0808 - accuracy: 0.9738 - val_loss: 0.2385 - val_accuracy: 0.9498\n",
      "Epoch 43/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0882 - accuracy: 0.9740 - val_loss: 0.2131 - val_accuracy: 0.9560\n",
      "Epoch 44/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.0797 - accuracy: 0.9757 - val_loss: 0.2105 - val_accuracy: 0.9571\n",
      "Epoch 45/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.3814 - val_accuracy: 0.9322\n",
      "Epoch 46/60\n",
      "1514/1514 [==============================] - 244s 161ms/step - loss: 0.0778 - accuracy: 0.9758 - val_loss: 0.2632 - val_accuracy: 0.9400\n",
      "Epoch 47/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0783 - accuracy: 0.9763 - val_loss: 0.1772 - val_accuracy: 0.9615\n",
      "Epoch 48/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.0732 - accuracy: 0.9756 - val_loss: 0.1805 - val_accuracy: 0.9677\n",
      "Epoch 49/60\n",
      "1514/1514 [==============================] - 240s 158ms/step - loss: 0.0785 - accuracy: 0.9760 - val_loss: 0.2576 - val_accuracy: 0.9519\n",
      "Epoch 50/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.5838 - val_accuracy: 0.9079\n",
      "Epoch 51/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0745 - accuracy: 0.9772 - val_loss: 0.2671 - val_accuracy: 0.9524\n",
      "Epoch 52/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0722 - accuracy: 0.9773 - val_loss: 0.2525 - val_accuracy: 0.9488\n",
      "Epoch 53/60\n",
      "1514/1514 [==============================] - 243s 160ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.3480 - val_accuracy: 0.9335\n",
      "Epoch 54/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.0599 - accuracy: 0.9813 - val_loss: 0.2252 - val_accuracy: 0.9591\n",
      "Epoch 55/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.0695 - accuracy: 0.9784 - val_loss: 0.2614 - val_accuracy: 0.9483\n",
      "Epoch 56/60\n",
      "1514/1514 [==============================] - 243s 161ms/step - loss: 0.0665 - accuracy: 0.9805 - val_loss: 0.3311 - val_accuracy: 0.9364\n",
      "Epoch 57/60\n",
      "1514/1514 [==============================] - 245s 162ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 0.2411 - val_accuracy: 0.9519\n",
      "Epoch 58/60\n",
      "1514/1514 [==============================] - 242s 160ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.5825 - val_accuracy: 0.8823\n",
      "Epoch 59/60\n",
      "1514/1514 [==============================] - 240s 159ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.2060 - val_accuracy: 0.9622\n",
      "Epoch 60/60\n",
      "1514/1514 [==============================] - 241s 159ms/step - loss: 0.0712 - accuracy: 0.9798 - val_loss: 0.1997 - val_accuracy: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f82fc4c5240>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCheck = tf.keras.callbacks.ModelCheckpoint('models/efficientnet_checkpoint.h5', monitor='val_loss', verbose=0, \n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "net_final.reset_states()\n",
    "net_final.fit_generator(train_batches, \n",
    "                        validation_data=val_batches,\n",
    "                        steps_per_epoch = int(len(train_batches.classes)/BATCH_SIZE)+1,\n",
    "                        validation_steps=len(val_batches.classes),\n",
    "                        epochs=60, \n",
    "                        callbacks=[ModelCheck],\n",
    "                       class_weight={i:class_weights[i] for i in range(len(BIRDS))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on val data\n",
      "3867/3867 [==============================] - 57s 15ms/step - loss: 0.1764 - accuracy: 0.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9637961983680725"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_final.load_weights('models/efficientnet_checkpoint.h5')\n",
    "print(\"Accuracy on val data\")\n",
    "net_final.evaluate(val_batches, steps=len(val_batches.classes))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
